{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the sigmoid function\n",
    "def sigmoid(z) -> float:\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with single training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 value is:  5\n",
      "x2 value is:  1\n",
      "y value is:  1\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression with single training example and two features\n",
    "# Features and label values initialization\n",
    "x1 = np.random.randint(10)\n",
    "x2 = np.random.randint(10)\n",
    "y = np.random.randint(2)\n",
    "\n",
    "print(\"x1 value is: \",x1)\n",
    "print(\"x2 value is: \",x2)\n",
    "print(\"y value is: \",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 value is:  0.7578\n",
      "w2 value is:  0.7623\n",
      "b value is:  0.9964\n"
     ]
    }
   ],
   "source": [
    "# Wieghts variables initialization\n",
    "w1 = np.random.random()\n",
    "w2 = np.random.random()\n",
    "b = np.random.random()\n",
    "\n",
    "print(\"w1 value is: \",round(w1,4))\n",
    "print(\"w2 value is: \",round(w2,4))\n",
    "print(\"b value is: \",round(b,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent hyperparameters (number of iterations and learning rates)\n",
    "num_iterations = 1000\n",
    "lr = 0.05\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    \n",
    "    #Forward propagation\n",
    "    z = w1 * x1 + w2 * x2 + b\n",
    "    a = sigmoid(z)\n",
    "    l= -((y * np.log(a) + (1-y) * (np.log(1-a))))\n",
    "    \n",
    "    #Backward Propagation\n",
    "    dz = a-y\n",
    "    dw1 = x1 * dz\n",
    "    dw2 = x2 * dz\n",
    "    db = dz\n",
    "    \n",
    "    #Wieghts update\n",
    "    w1 = w1 - lr * dw1\n",
    "    w2 = w2 - lr * dw2\n",
    "    b  = b  - lr * db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 ultimate value is:  1.0974\n",
      "w2 ultimate value is:  0.8303\n",
      "b ultimate value is:  1.0643\n",
      "predected label ultimate value is:  0.9994\n"
     ]
    }
   ],
   "source": [
    "#Ultimate weight values\n",
    "print(\"w1 ultimate value is: \",round(w1,4))\n",
    "print(\"w2 ultimate value is: \",round(w2,4))\n",
    "print(\"b ultimate value is: \",round(b,4))\n",
    "print(\"predected label ultimate value is: \",round(a,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with m training example (Non-vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training examples values:\n",
      " [[2 8 8 ... 1 4 9]\n",
      " [8 4 3 ... 0 1 4]]\n",
      "training labels values:\n",
      " [[1 1 1 ... 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression with single 10 example and two features\n",
    "# Features and label values initialization\n",
    "m = 10\n",
    "n = 2\n",
    "X = np.random.randint(10,size=(n,m))\n",
    "Y = np.random.randint(2, size=(1,m))\n",
    "\n",
    "print('training examples values:\\n', X)\n",
    "print('training labels values:\\n', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 value is:  0.0\n",
      "w2 value is:  0.0\n",
      "b value is:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Wieghts variables initialization\n",
    "w1 = 0.\n",
    "w2 = 0.\n",
    "b = 0.\n",
    "\n",
    "print(\"w1 value is: \",round(w1,4))\n",
    "print(\"w2 value is: \",round(w2,4))\n",
    "print(\"b value is: \",round(b,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent hyperparameters (number of iterations and learning rates)\n",
    "num_iterations = 10000\n",
    "lr = 0.01\n",
    "#cost function and Derivatives initialization\n",
    "J = 0.\n",
    "dw1 = 0.\n",
    "dw2 = 0.\n",
    "db = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "for iteration in range(num_iterations):\n",
    "    \n",
    "    for i in range(len(X.T)):\n",
    "        #Forward propagation\n",
    "        zi = w1 * X[:,i][0] + w2 * X[:,i][1] + b\n",
    "        ai = sigmoid(zi)\n",
    "        J += -((Y[0][i] * np.log(ai) + (1-Y[0][i]) * (np.log(1-ai))))\n",
    "        \n",
    "        #backward propagation\n",
    "        dzi = ai - Y[0][i]\n",
    "        dw1 += X[:,i][0] * dzi\n",
    "        dw2 += X[:,i][1] * dzi\n",
    "        db += dzi\n",
    "\n",
    "    #Cost function and derivatives averaging   \n",
    "    J /= m\n",
    "    dw1 /= m\n",
    "    dw2 /= m\n",
    "    db /= m\n",
    "    # Weights update\n",
    "    w1 = w1 - lr * dw1\n",
    "    w2 = w2 - lr * dw2\n",
    "    b  = b  - lr * db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 ultimate value is:  -0.0\n",
      "w2 ultimate value is:  -0.01\n",
      "b ultimate value is:  0.02\n"
     ]
    }
   ],
   "source": [
    "#Ultimate weight values\n",
    "print(\"w1 ultimate value is: \",round(w1,2))\n",
    "print(\"w2 ultimate value is: \",round(w2,2))\n",
    "print(\"b ultimate value is: \",np.round(b,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_y(x1: float, x2:float) -> float:\n",
    "    return round(sigmoid(w1 * x1 + w2 * x2 + b),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 =  4    x2 =  4    y =  1\n",
      "pridicted y label       =  0.44 \n",
      "\n",
      "x1 =  9    x2 =  9    y =  0\n",
      "pridicted y label       =  0.57 \n",
      "\n",
      "x1 =  4    x2 =  4    y =  0\n",
      "pridicted y label       =  0.67 \n",
      "\n",
      "x1 =  7    x2 =  7    y =  1\n",
      "pridicted y label       =  0.45 \n",
      "\n",
      "x1 =  4    x2 =  4    y =  1\n",
      "pridicted y label       =  0.76 \n",
      "\n",
      "x1 =  9    x2 =  9    y =  1\n",
      "pridicted y label       =  0.9 \n",
      "\n",
      "x1 =  0    x2 =  0    y =  1\n",
      "pridicted y label       =  0.54 \n",
      "\n",
      "x1 =  3    x2 =  3    y =  0\n",
      "pridicted y label       =  0.44 \n",
      "\n",
      "x1 =  0    x2 =  0    y =  0\n",
      "pridicted y label       =  0.48 \n",
      "\n",
      "x1 =  6    x2 =  6    y =  1\n",
      "pridicted y label       =  0.81 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X.T)):\n",
    "    \n",
    "    print('x1 = ', X[:,i][0],\n",
    "          '  ', 'x2 = ', X[:,i][0],\n",
    "          '  ', 'y = ', Y[0][i])\n",
    "    \n",
    "    print('pridicted y label       = ',\n",
    "         predict_y(X[:,i][0], X[:,i][1]), \n",
    "          '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with m training example (Vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training examples values:\n",
      " [[0 8 3 3 9 4 4 6 2 8]\n",
      " [1 1 4 1 5 4 5 4 6 7]]\n",
      "training labels values:\n",
      " [[0 1 0 1 1 0 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression with single 10 example and two features\n",
    "# Features and label values initialization\n",
    "m = 10\n",
    "n = 2\n",
    "X = np.random.randint(10,size=(n,m))\n",
    "Y = np.random.randint(2, size=(1,m))\n",
    "\n",
    "print('training examples values:\\n', X)\n",
    "print('training labels values:\\n', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight variables value are: \n",
      " [[0.]\n",
      " [0.]]\n",
      "bias variables value are:  0\n"
     ]
    }
   ],
   "source": [
    "# Wieghts variables initialization\n",
    "w = np.zeros(shape = (n,1))\n",
    "b = 0\n",
    "print(\"weight variables value are: \\n\",w)\n",
    "print(\"bias variables value are: \",np.round(b,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent hyperparameters (number of iterations and learning rates)\n",
    "num_iterations = 10000\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_iterations):\n",
    "    #Forward propagation\n",
    "    Z = np.dot(w.T,X)\n",
    "    A = sigmoid(Z)\n",
    "    cost = (-1/m)*(np.dot(Y,np.log(A).T)+ np.dot((1-Y),np.log(1-A).T))\n",
    "    \n",
    "    #Backward propagation\n",
    "    dZ = A-Y\n",
    "    dw = (1/m) * np.dot(X, dZ.T)\n",
    "    db1 = (1/m) * np.sum(dZ)\n",
    "    \n",
    "    #Weights updatae\n",
    "    w = w - lr * dw\n",
    "    b = b - lr * db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w ultimate value is: \n",
      " [[ 0.]\n",
      " [-0.]] \n",
      "\n",
      "b ultimate value is:  0.09\n"
     ]
    }
   ],
   "source": [
    "#Ultimate weight values\n",
    "print(\"w ultimate value is: \\n\",np.round(w,2),'\\n')\n",
    "print(\"b ultimate value is: \", np.round(b,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
