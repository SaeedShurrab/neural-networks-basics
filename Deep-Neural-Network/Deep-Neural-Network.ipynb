{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Related Libraries Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions Defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions defination\n",
    "def activation_fun(x,activation_type= 'sigmoid'):\n",
    "    \n",
    "    if activation_type not in ['sigmoid','tanh', 'relu','lrelu']:\n",
    "        raise ValueError(\" activation type must be in ['sigmoid','tanh', 'relu','lrelu']\")\n",
    "    \n",
    "    if activation_type == 'sigmoid':\n",
    "        return (1/(1+np.exp(-x)))\n",
    "    \n",
    "    elif activation_type == 'tanh':\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    elif activation_type == 'relu':\n",
    "        return np.maximum(0.0,x)\n",
    "    \n",
    "    elif activation_type == 'lrelu':\n",
    "        return np.maximum(0.01 * x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation fumnctions derivatives\n",
    "def act_derivative(x, activation_type= 'sigmoid'):\n",
    "\n",
    "    if activation_type not in ['sigmoid','tanh', 'relu','lrelu']:\n",
    "        raise ValueError(\" activation type must be in ['sigmoid','tanh', 'relu','lrelu']\")    \n",
    "    \n",
    "    if activation_type == 'sigmoid':\n",
    "        return activation_fun(x, activation_type= activation_type)\\\n",
    "        * (1- activation_fun(x, activation_type=activation_type))\n",
    "    \n",
    "    elif activation_type == 'tanh':\n",
    "        return 1- (activation_fun(x,activation_type= activation_type))**2\n",
    "    \n",
    "    elif activation_type == 'relu':\n",
    "        return np.where(x <= 0.0, 0.0,1.0)\n",
    "    \n",
    "    elif activation_type == 'lrelu':\n",
    "        return np.where(x <= 0.0, 0.01 * x,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random data generation for function\n",
    "def data_generator(num_features=10, num_examples=1000,train_p=0.8):\n",
    "    \n",
    "    dataset = np.random.randint(0,20,size=(num_features,num_examples))\n",
    "    labels = np.random.randint(0,2,(1,num_examples))\n",
    "    \n",
    "    x_train = dataset[:,:int(num_examples * train_p)]\n",
    "    y_train = labels[:,:int(num_examples * train_p)]\n",
    "    x_test = dataset[:,int(num_examples * train_p) :]\n",
    "    y_test = labels[:,int(num_examples * train_p):]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = data_generator(num_features=5, num_examples=10, train_p=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters initiation\n",
    "def initialize_parameters(layer_dims):\n",
    "    \n",
    "    parameters ={}\n",
    "    L = len(layer_dims)\n",
    "    for l in range(1,L):\n",
    "        parameters['W'+ str(l)] =  np.random.randn(layer_dims[l],layer_dims[l-1])*0.1\n",
    "        parameters['b'+ str(l)] =  np.zeros((layer_dims[l],1))\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.08087733,  0.0664122 , -0.12097279,  0.03025323, -0.09484008],\n",
       "        [ 0.18561727, -0.16058276,  0.10141466,  0.03732837, -0.02113285],\n",
       "        [-0.0697803 ,  0.11311399,  0.14349171,  0.01416696, -0.00130067]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[-0.19898727, -0.03565914,  0.07408392],\n",
       "        [ 0.01240134,  0.13237066, -0.08097276],\n",
       "        [-0.09831711, -0.04112334, -0.00549575]]),\n",
       " 'b2': array([[0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W3': array([[ 0.05263844, -0.1264592 , -0.10143666]]),\n",
       " 'b3': array([[0.]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims = [5,3,3,1]\n",
    "parameters = initialize_parameters(dims)\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(A_prev, parameters, activation_order):\n",
    "    \n",
    "    cache = {}\n",
    "    \n",
    "    for  l,activation in enumerate(activation_order):\n",
    "        \n",
    "        W = parameters['W' + str(l+1)]\n",
    "        b = parameters['b' + str(l+1)]\n",
    "       \n",
    "        Z = np.dot(W,A_prev) + b\n",
    "        A = activation_fun(Z,activation_type= activation)\n",
    "        \n",
    "        cache['Z' + str(l+1)]= Z\n",
    "        cache['A' + str(l+1)]= A\n",
    "        \n",
    "        A_prev = A\n",
    "    \n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Z1': array([[-1.00132224,  0.21216916,  1.15334123, -0.53510064,  1.53005562,\n",
       "         -0.37912496, -1.46926466,  0.24713178],\n",
       "        [ 1.79620196,  1.05677128,  2.15841101,  2.53568404,  3.55308581,\n",
       "          2.96615513,  4.83402986,  3.76568277],\n",
       "        [ 1.81835641,  0.874745  ,  0.42301606,  1.55134248, -0.33169235,\n",
       "          0.04865744,  1.9165236 ,  0.13493678]]),\n",
       " 'A1': array([[0.        , 0.21216916, 1.15334123, 0.        , 1.53005562,\n",
       "         0.        , 0.        , 0.24713178],\n",
       "        [1.79620196, 1.05677128, 2.15841101, 2.53568404, 3.55308581,\n",
       "         2.96615513, 4.83402986, 3.76568277],\n",
       "        [1.81835641, 0.874745  , 0.42301606, 1.55134248, 0.        ,\n",
       "         0.04865744, 1.9165236 , 0.13493678]]),\n",
       " 'Z2': array([[ 0.07065996, -0.01509797, -0.27512861,  0.02450923, -0.43116156,\n",
       "         -0.1021658 , -0.03039375, -0.17346044],\n",
       "        [ 0.0905271 ,  0.07168618,  0.26576049,  0.21003369,  0.48929906,\n",
       "          0.38869199,  0.48469752,  0.49060448],\n",
       "        [-0.08385904, -0.0691252 , -0.20447903, -0.11280158, -0.2965454 ,\n",
       "         -0.12224561, -0.20932417, -0.17989631]]),\n",
       " 'A2': array([[0.07065996, 0.        , 0.        , 0.02450923, 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.0905271 , 0.07168618, 0.26576049, 0.21003369, 0.48929906,\n",
       "         0.38869199, 0.48469752, 0.49060448],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]),\n",
       " 'Z3': array([[-0.00772855, -0.00906538, -0.03360786, -0.02527056, -0.06187637,\n",
       "         -0.04915368, -0.06129446, -0.06204145]]),\n",
       " 'A3': array([[0.49806787, 0.49773367, 0.49159883, 0.49368269, 0.48453584,\n",
       "         0.48771405, 0.48468118, 0.48449461]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations = ['relu','relu','sigmoid']\n",
    "cache = forward_prop(x_train,parameters,activations)\n",
    "cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Y, cache):\n",
    "    \n",
    "    AL = cache[(list(cache.keys())[-1])]\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    cost = np.squeeze((-1/m)*(np.dot(Y,np.log(AL).T)+ np.dot((1-Y),np.log(1-AL).T)))\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = compute_cost(y_train,cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(X,Y,parameters,cache, activation_order):\n",
    "    \n",
    "    AL = cache['A'+str(len(activation_order))]\n",
    "    grads = {}\n",
    "    dA =  - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    \n",
    "    for l, activation in reversed(list(enumerate(activation_order))):\n",
    "        \n",
    "        Z = cache['Z' + str(l+1)]\n",
    "        \n",
    "        if l == 0:\n",
    "            A_prev = X\n",
    "        else:\n",
    "            A_prev = cache['A' + str(l)]\n",
    "            \n",
    "        W = parameters['W' + str(l+1)]\n",
    "        \n",
    "        dZ = dA * act_derivative(Z, activation_type= activation)\n",
    "        dW = (1/m) * np.dot(dZ,A_prev.T)\n",
    "        db =  (1/m) * np.sum(np.dot(dZ, A_prev.T), axis = 1, keepdims =True)\n",
    "        dA = np.dot(W.T,dZ)\n",
    "        \n",
    "        grads['dW'+ str(l+1)] = dW\n",
    "        grads['db'+ str(l+1)] = db\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = backward_prop(x_train,y_train, parameters,cache,activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(parameters, grads, learning_rate = 0.01):\n",
    "    \n",
    "    L = int(len(grads)/2)+1\n",
    "    \n",
    "    for l in range(1,L):\n",
    "        \n",
    "        W = parameters['W' + str(l)]\n",
    "        b = parameters['b' + str(l)]\n",
    "        \n",
    "        dW = grads['dW' + str(l)]\n",
    "        db = grads['db' + str(l)]\n",
    "        \n",
    "        parameters['W' + str(l)] = W - learning_rate * dW\n",
    "        parameters['b' + str(l)] = b - learning_rate * db\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = optimize(parameters,grads, learning_rate=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X,Y, layer_dims, activation_order, num_iterations=5000,learning_rate = 0.01,print_cost=False):\n",
    "    \n",
    "    parameters = initialize_parameters(layer_dims)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "    \n",
    "        cache = forward_prop(X, parameters, activation_order)\n",
    "        \n",
    "        cost = compute_cost(Y,cache)\n",
    "        \n",
    "        grads = backward_prop(X,Y,parameters,cache,activation_order)\n",
    "        \n",
    "        parameters = optimize(parameters,grads,learning_rate)\n",
    "        \n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.696959\n",
      "Cost after iteration 1000: 0.637997\n",
      "Cost after iteration 2000: 2.437065\n",
      "Cost after iteration 3000: 0.566539\n",
      "Cost after iteration 4000: 2.473683\n"
     ]
    }
   ],
   "source": [
    "parameters = model(x_train,y_train,dims,activations,print_cost=True, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters, activation_order):\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    cache = forward_prop(X,parameters,activation_order)\n",
    "    probas = cache[(list(cache.keys())[-1])]\n",
    "\n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    \n",
    "    print(\"Accuracy: \"  + str(np.sum((p == y)/m)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'h5py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9391a382fc35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mndimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'h5py'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "# for windows os flip the forward slash (/) into backward slash (\\)\n",
    "os.chdir('../utils')\n",
    "from lr_utils import load_dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-155b498c1005>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_x_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_x_orig, train_y, test_x_orig, test_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x_orig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-65a81ffa454a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m19\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x_orig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"y = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\". It's a \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0;34m\" picture.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_x_orig' is not defined"
     ]
    }
   ],
   "source": [
    "index = 19\n",
    "plt.imshow(train_x_orig[index])\n",
    "print (\"y = \" + str(train_y[0,index]) + \". It's a \" + classes[train_y[0,index]].decode(\"utf-8\") +  \" picture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 209\n",
      "Number of testing examples: 50\n",
      "Each image is of size: (64, 64, 3)\n",
      "train_x_orig shape: (209, 64, 64, 3)\n",
      "train_y shape: (1, 209)\n",
      "test_x_orig shape: (50, 64, 64, 3)\n",
      "test_y shape: (1, 50)\n"
     ]
    }
   ],
   "source": [
    "m_train = train_x_orig.shape[0]\n",
    "num_px = train_x_orig.shape[1]\n",
    "m_test = test_x_orig.shape[0]\n",
    "\n",
    "print (\"Number of training examples: \" + str(m_train))\n",
    "print (\"Number of testing examples: \" + str(m_test))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_x_orig shape: \" + str(train_x_orig.shape))\n",
    "print (\"train_y shape: \" + str(train_y.shape))\n",
    "print (\"test_x_orig shape: \" + str(test_x_orig.shape))\n",
    "print (\"test_y shape: \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x's shape: (12288, 209)\n",
      "test_x's shape: (12288, 50)\n"
     ]
    }
   ],
   "source": [
    "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
    "\n",
    "# Standardize data to have feature values between 0 and 1.\n",
    "train_x = train_x_flatten/255.\n",
    "test_x = test_x_flatten/255.\n",
    "\n",
    "print (\"train_x's shape: \" + str(train_x.shape))\n",
    "print (\"test_x's shape: \" + str(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.704070\n",
      "Cost after iteration 1000: 0.640192\n",
      "Cost after iteration 2000: 0.600308\n",
      "Cost after iteration 3000: 0.461689\n",
      "Cost after iteration 4000: 0.142571\n",
      "Cost after iteration 5000: 0.030624\n",
      "Cost after iteration 6000: 0.004066\n"
     ]
    }
   ],
   "source": [
    "dims = [12288,20,7,5,1]\n",
    "activations = ['relu','relu','relu','sigmoid']\n",
    "parameters = model(train_x,train_y,dims,activations,print_cost=True, learning_rate=0.0075,num_iterations= 6100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "predict(train_x,train_y,parameters,activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "predict(test_x,test_y,parameters,activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the end of the story"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
